{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as 'workload_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate time series data\n",
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start='2021-01-01', end='2024-12-31', freq='D')\n",
    "days = len(date_range)\n",
    "\n",
    "# Define base workload values (random workload between 1 and 3, simulating light days)\n",
    "workload = np.random.normal(loc=2.5, scale=0.5, size=days)\n",
    "\n",
    "# Introduce seasonality for peaks (amplified workload) around March and September\n",
    "seasonal_factor = np.sin(2 * np.pi * date_range.dayofyear / 365) * 1.5  # Yearly seasonality\n",
    "workload += seasonal_factor\n",
    "\n",
    "# Introduce peaks during March (mid-terms) and September (end-semester)\n",
    "for month in [3, 9]:  # March and September peaks\n",
    "    month_mask = (date_range.month == month)\n",
    "    \n",
    "    # Add random peak workload during exam periods\n",
    "    workload[month_mask] += np.random.normal(2.5, 0.5, sum(month_mask))\n",
    "    \n",
    "    # Introduce random drops after exams\n",
    "    workload[month_mask & (date_range.day > 20)] = np.random.uniform(0, 1.5, sum(month_mask & (date_range.day > 20)))\n",
    "\n",
    "# Simulate some \"rest\" periods after exams (e.g., after March, September)\n",
    "for rest_month in [4, 10]:\n",
    "    rest_mask = (date_range.month == rest_month) & (date_range.day < 10)\n",
    "    workload[rest_mask] = np.random.uniform(0, 1, sum(rest_mask))  # Minimal workload after exams\n",
    "\n",
    "# Introduce random fluctuations even in low-workload months\n",
    "random_fluctuation = np.random.normal(0, 0.2, size=days)\n",
    "workload += random_fluctuation\n",
    "\n",
    "# Clip the workload to the scale of 0 to 5 (0 represents no workload)\n",
    "workload = np.clip(workload, 0, 5)\n",
    "\n",
    "# Round the 'Workload' column to 1 decimal place\n",
    "workload = workload.round(1)\n",
    "\n",
    "# Create DataFrame\n",
    "workload_data = pd.DataFrame({\n",
    "    'Date': date_range,\n",
    "    'Workload': workload\n",
    "})\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "workload_data.to_csv('workload_time_series.csv', index=False)\n",
    "\n",
    "print(\"Dataset saved as 'workload_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Question_Difficulty  Total_Questions  Short_Questions_Included  \\\n",
      "0                    4               16                         0   \n",
      "1                    5               11                         0   \n",
      "2                    3               13                         1   \n",
      "3                    5               12                         0   \n",
      "4                    5               16                         0   \n",
      "\n",
      "   Long_Questions_Included  Long_Question_Proportion  \n",
      "0                        0                      0.00  \n",
      "1                        1                      0.42  \n",
      "2                        0                      0.00  \n",
      "3                        0                      0.00  \n",
      "4                        1                      0.46  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters for dataset generation\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_rows = 100\n",
    "\n",
    "# Generating random data for features\n",
    "difficulty = np.random.randint(1, 6, n_rows)  # Difficulty between 1-5\n",
    "total_questions = np.random.randint(5, 21, n_rows)  # Total number of questions (5-20)\n",
    "\n",
    "# Binary columns for short and long question types\n",
    "short_questions_included = np.random.choice([0, 1], n_rows)  # 0 = No, 1 = Yes\n",
    "long_questions_included = np.random.choice([0, 1], n_rows)  # 0 = No, 1 = Yes\n",
    "\n",
    "# Target: Proportion of long questions (0 to 1)\n",
    "# Assuming long_questions_proportion is influenced by the difficulty, total_questions, and long_questions_included\n",
    "long_question_proportion = np.where(long_questions_included == 1, \n",
    "                                    np.clip(difficulty / 10 + np.random.normal(0, 0.1, n_rows), 0, 1), \n",
    "                                    0)\n",
    "\n",
    "# Round Long_Question_Proportion to 2 decimal places\n",
    "long_question_proportion = np.round(long_question_proportion, 2)\n",
    "\n",
    "# Creating the dataset\n",
    "data = pd.DataFrame({\n",
    "    'Question_Difficulty': difficulty,\n",
    "    'Total_Questions': total_questions,\n",
    "    'Short_Questions_Included': short_questions_included,\n",
    "    'Long_Questions_Included': long_questions_included,\n",
    "    'Long_Question_Proportion': long_question_proportion\n",
    "})\n",
    "\n",
    "# Display first few rows of the generated dataset\n",
    "print(data.head())\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "data.to_csv('dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 rows of synthetic data and saved to 'synthetic_assignment_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the number of rows to generate\n",
    "num_rows = 500\n",
    "\n",
    "# Define ranges and distributions for each column\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "data = {\n",
    "    \"assignment_difficulty\": np.random.randint(1, 6, num_rows),  # Difficulty between 1 and 5\n",
    "    \"active_assignments_count\": np.random.randint(0, 8, num_rows),  # Active assignments between 0 and 7\n",
    "    \"question_type_distribution\": np.round(np.random.uniform(0.4, 0.75, num_rows), 2),  # Distribution between 0.4 and 0.75\n",
    "    \"workload\": np.round(np.random.uniform(1.5, 5.0, num_rows), 2),  # Workload between 1.5 and 5.0\n",
    "    \"historical_avg_completion_time\": np.round(np.random.uniform(3.5, 7.0, num_rows), 2)  # Completion time between 3.5 and 7.0\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('synthetic_assignment_data.csv', index=False)\n",
    "print(\"Generated 500 rows of synthetic data and saved to 'synthetic_assignment_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
